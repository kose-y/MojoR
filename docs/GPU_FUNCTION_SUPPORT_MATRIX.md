# GPU Function Support Matrix

This is the canonical GPU function support matrix for MÃ¶joR.
Use this page when you need one answer for: "Can this function/surface run on GPU, under what constraints, and with what fallback behavior?"
For mode definitions (`gpu_jit_mode`, `ir_only`, `object_mode`, `semantics`), see `docs/PIPELINE/API.md`.

## Notation Key

- `L*` = IR constructor/verifier/emitter support level.
- `S*` = runtime `GPUArray`/class support level.

Support levels:

- `L4`/`S4`: strong end-to-end support in normal lanes.
- `L3`/`S3`: supported with explicit constraints and route gating.
- `L2`/`S2`: partial/deferred or host-seeded support.
- `L1`/`S1`: compatibility-only, unsupported, or intentionally absent.

## Canonical Matrix

| Function/surface | Layer | Target | Support level | DType support | Shape/rank constraints | Strict-mode constraints | Fallback behavior and route labels | Representative diagnostics | Owner doc |
|---|---|---|---|---|---|---|---|---|---|
| `mojor_vectorize(..., target="gpu")` | wrapper | both | `L3` | Mostly numeric lanes; backend dependent | Elementwise kernels; route depends on emitted GPU lane | Strict compile behavior depends on wrapper and options | GPU lane on success; explicit CPU/object-mode routing in compatible lanes | Wrapper compile/runtime route mismatches in strict lanes | `docs/PIPELINE/API.md`, `docs/COOKBOOK.md` |
| `mojor_guvectorize(..., target="gpu")` | wrapper | gpu | `L3` | Numeric subset; backend dependent | Core-dims subset grammar with rank/tuple constraints | GPU target is strict: compile failures are explicit | No silent CPU downgrade for strict GPU target | `mojor_guvectorize: gpu target core kernel ... failed strict compilation` | `docs/COOKBOOK.md`, `docs/TROUBLESHOOTING.md` |
| `.mojor_ir_gpu_reduce(op, arg, dims, keepdims)` | IR DSL | gpu | `L3` | IR type env gates numeric matrix/vector lanes | Lowering accepts `dims`/`keepdims` in `auto` and `unified_preview` modes (runtime/capability still determines GPU vs CPU reduce path) | `op` must be in `{sum, mean, prod, min, max, argmin, argmax}` | Route chosen during lowering/emission; runtime may label `gpu_reduce` or `cpu_reduce` | `IR verify [gpu_reduce]: unsupported op '<op>'` | `docs/IR/FUNCTION_SUPPORT_BREADTH.md` |
| `.mojor_ir_gpu_matmul(a, b, transpose_a, transpose_b)` | IR DSL | gpu | `L3` | Strict mode requires matching matrix element types | Matrix-typed operands; expression/assign form gates apply | Expression form requires `gpu_jit_mode` in `{auto, unified_preview}` | Runtime routes `gpu_matmul` or `cpu_matmul` by capability | `IR verify [gpu_matmul]: expression form requires gpu_jit_mode='auto' or 'unified_preview'` | `docs/IR/FUNCTION_SUPPORT_BREADTH.md` |
| `GPUArray(...)`, `mojor_gpu_array(...)`, `gpu_array(...)` | GPUArray runtime | gpu | `S4` | `f32`, `f64`, `i32` (backend capability dependent) | Positive extent checks for `dim`/`n` forms | N/A | Constructor routes follow backend availability; explicit errors on invalid shape/input | `mojor_gpu_array: provide x or n`, `gpu_zeros: provide dim or n` | `docs/GPUARRAY_CLASS_SUPPORT.md` |
| `gpu_zeros`, `gpu_ones`, `gpu_full`, `gpu_empty` | GPUArray runtime | gpu | `S4` | `f32`, `f64`, `i32` | `dim` must be non-empty positive extents (or positive `n`) | N/A | Constructor-like route behavior; no implicit host fallback for invalid shape/input | `gpu_zeros: dim entries must be positive`, `gpu_full: value must be a non-NA numeric scalar` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `gpu_zeros_like`, `gpu_ones_like`, `gpu_full_like`, `gpu_empty_like` | GPUArray runtime | gpu | `S4` | Inherits from source (`auto`) or explicit `dtype` | Source must have positive length/valid shape metadata | N/A | Like-shape allocation route; explicit shape/value checks | `gpu_empty_like: x must have positive length` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `gpu_rand`, `gpu_randn`, `gpu_randi`, `gpu_rand_like`, `gpu_randn_like`, `gpu_randi_like` | GPUArray runtime | both | `S2` | `f32`, `f64`, `i32` (`gpu_randi*` integer-valued) | Same shape constraints as allocators; RNG bounds/params validated | N/A | Host-generated samples uploaded to GPU buffers | `gpu_randi: n must be positive`, `gpu_randn_like: x must have positive length` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `mojor_gpu_array_read`, `mojor_gpu_array_write`, `mojor_gpu_array_free` | GPUArray runtime | both | `S4` | `f32`, `f64`, `i32` | Write length must match buffer length; handle required | N/A | Read/write routes may touch host memory; free clears handle/metadata | `mojor_gpu_array_write: length mismatch`, `mojor_gpu_array_read: missing handle` | `docs/GPUARRAY_CLASS_SUPPORT.md` |
| `as.GPUArray`, `as.array.GPUArray`, `as.matrix.GPUArray`, `as.numeric.GPUArray` | GPUArray runtime | both | `S4` | `f32`, `f64`, `i32` | Source must be coercible; device handle required for materialization | N/A | Existing `GPUArray` passes through; host materialization on `as.*` reads | `mojor_gpu_array_read: missing handle` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `Ops.GPUArray` (arithmetic `+ - * / ^ %% %/%` unary `+/-`; comparisons `< > <= >= == !=`; logical `! & \|`) | GPUArray runtime | both | `S3` | Numeric lanes (`f32`, `f64`, `i32`) with promotion/cast rules | Elementwise-compatible shapes and scalar lanes only | N/A | Arithmetic routes via GPU kernels when supported; comparison/logical lanes currently route through explicit CPU labels (`cpu_compare`, `cpu_logic`) and return typed `GPUArray` outputs | `mojor_gpu: unsupported operator '<op>'`, `mojor_gpu: unsupported operand types` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| Function-style binary math (`gpu_atan2`, `gpu_minimum`, `gpu_maximum`) | GPUArray runtime | both | `S3` | Numeric lanes with promotion/cast rules (`gpu_atan2` promotes integer lanes to float output) | Elementwise-compatible shapes and scalar lanes; `gpu_minimum`/`gpu_maximum` are variadic folds; `na.rm = TRUE` routes explicit host parity; scalar-host-lhs `gpu_minimum`/`gpu_maximum` preserve base parity by dropping `dim`/`dimnames` | N/A | GPU-first elementwise dispatch; success may be direct GPU (no `gpu_fallback`) or CPU-tagged (`cpu_kernel_host`, `cpu_arith`). Locked `cpu_arith` reason-code lanes: `kernel_dispatch_failed` (kernel-fail across `arr_arr`/`arr_sca`/`sca_arr`, including `gpu_atan2` when backend intrinsics are unavailable), `na_rm_host_parity`, `shape_mismatch_host_parity` | `mojor_gpu: unsupported binary math function '<fn>'`, `mojor_gpu: unsupported operand types` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| Direct numeric `Math`/`round` on `GPUArray` (`sin`, `cos`, `tan`, `exp`, `log`, `log10`, `log2`, `log1p`, `expm1`, `sqrt`, `abs`, `sign`, `trunc`, `round`, `floor`, `ceiling`) | GPUArray runtime | both | `S3` | `f32`, `f64` (direct); `i32` routes through cast/promotion for transcendental lanes | Unary elementwise inputs; `round` accepts scalar `digits` with GPU-first route for `digits = 0` and host fallback otherwise; `log10`/`log2`/`sign` use lowered GPU-kernel expressions before fallback | N/A | GPU-first unary dispatch; direct raw-GPU success may have no `gpu_fallback` attr. Locked `cpu_arith` reason-code lanes: `raw_kernel_unavailable`, `kernel_dispatch_failed`, `round_digits_host_fallback` | `mojor_gpu: unsupported Math operator '<op>'` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md`, `docs/COOKBOOK.md` |
| Internal GPU memoization diagnostics (`.mojor_gpu_capability_cache_diag`, `.mojor_gpu_kernel_cache_diag`, `.mojor_gpu_cache_diag`) | GPUArray runtime | both | `S2` | N/A (diagnostic metadata) | Internal/helper surface for test/audit lanes | N/A | Read-only snapshots of capability/kernel cache entries plus memoization counters (`lookups`, `hits`, `misses`, `negative_hits`, `stores`); optional `reset=TRUE` counter reset | Internal helper contract (dot-prefixed; no stable end-user API guarantee) | `docs/GPUARRAY_GUIDE.md` |
| `Summary.GPUArray`/`mean.GPUArray`/`gpu_which_min`/`gpu_which_max` | GPUArray runtime | both | `S3` | Numeric lanes (`f32`, `f64`, `i32`) | Scalar reductions for direct single-array lanes; multi-arg/`na.rm`/trimmed forms use host parity. `gpu_which_min`/`gpu_which_max` are canonical for index reducers; base `which.min`/`which.max` dispatch is compatibility-only in some R6-backed call paths | N/A | GPU-first scalar reduction lanes via `gpu_*` reducers when eligible; explicit host parity for broader/base-compatible forms | `mojor_gpu: unsupported Summary operator '<op>'` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `gpu_cast(x, dtype)` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` | Array-like cast lanes; capability gated | N/A | `gpu_cast` -> `cpu_cast`/`host_cast` when unsupported | `gpu_cast: x must be numeric/integer or mojor_gpu_array` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `gpu_promote(x, y)` | GPUArray runtime | both | `S3` | Promotes within numeric lanes (`f32`, `f64`, `i32`) | Inputs must be numeric-like or `GPUArray` for both operands | N/A | Returns promoted pair; internally routes via `gpu_cast` and may CPU/host-fallback per cast route | `mojor_gpu: unsupported operand types` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `gpu_broadcast(x, shape)` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` | Shape must be broadcast-compatible | N/A | `gpu_broadcast` -> `cpu_broadcast`/`host_broadcast` when unsupported | `gpu_broadcast: x must be numeric/integer or mojor_gpu_array` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `gpu_reduce`, `gpu_sum`, `gpu_mean`, `gpu_prod`, `gpu_min`, `gpu_max`, `gpu_pmin`, `gpu_pmax`, `gpu_argmin`, `gpu_argmax` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` (route/capability dependent) | `op` fixed set; dims must be valid for rank | N/A | `gpu_reduce` -> `cpu_reduce` when unsupported or gated | `mojor_gpu_reduce: invalid dims`, `mojor_gpu_reduce: op must be a single character string` | `docs/GPUARRAY_CLASS_SUPPORT.md` |
| `gpu_matmul`, `gpu_matmul_into`, `%*%.GPUArray` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` (capability dependent; mixed GPUArray dtypes auto-promote) | Inputs must be 2D and inner dims must match; output contract checks in `*_into` | N/A | `gpu_matmul` -> `cpu_matmul`; explicit fallback reasons on gated modes | `mojor_gpu_matmul: inner dimensions must match`, `mojor_gpu_matmul: output dtype mismatch` | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/TROUBLESHOOTING.md` |
| `crossprod.GPUArray`, `tcrossprod.GPUArray` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` (capability/gating dependent; mixed GPUArray dtypes auto-promote) | Matrix-compatible shapes via matmul-view dispatch rules | N/A | GPU-first (`gpu_crossprod`/`gpu_tcrossprod`) with explicit CPU fallback routes (`cpu_crossprod`/`cpu_tcrossprod`) | Matmul-shape and dtype contract failures surfaced through shared linalg dispatch | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/GPUARRAY_GUIDE.md` |
| `[.GPUArray`, `[<-.GPUArray`, `gpu_slice` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` | Canonical selector forms use GPU-first indexing paths; broader selector classes (including non-canonical ND `NULL` selectors) use explicit host-parity fallback | N/A | Index routes: `gpu_slice`/`gpu_gather`/`gpu_scatter` with CPU downgrades (`cpu_slice`, `cpu_gather`, `cpu_scatter`, `cpu_slice_assign`); non-unit/irregular `gpu_slice` now attempts GPU gather before CPU fallback (including plan-cache-miss lanes); empty-index lanes return empty `GPUArray` results on both device-native gather and host-parity fallback routes; assignment families auto-align GPUArray replacement dtypes to target dtype | `[.mojor_gpu_array: logical mask must not contain NA`, `[<-.mojor_gpu_array: number of items to replace is not a multiple of replacement length`, `gpu_slice: strides must be non-zero` | `docs/GPUARRAY_CLASS_SUPPORT.md` |
| `[[.GPUArray`, `[[<-.GPUArray`, `$.GPUArray`, `$<-.GPUArray` | GPUArray runtime | both | `S3` | `f32`, `f64`, `i32` | `[[`/`[[<-` require a single-element target selection (supports rank>1 scalar linear parity plus tuple-style multi-axis selectors); `$`/`$<-` read/write metadata fields and unique dimname-axis keys | N/A | `[[` uses scalar extraction routes with base-style rank>1 linear-index parity for scalar selectors; `[[<-` supports corresponding scalar linear assignment parity and otherwise routes through bracket assignment lanes; `$` resolves metadata first, then dimname-axis extraction when unique; `$<-` supports metadata field writes and dimname-axis replacement | `[[.mojor_gpu_array: index must select exactly one element`, `[[<-.mojor_gpu_array: character replacement is not supported`, `$<-.mojor_gpu_array: unknown field or dimname axis` | `docs/GPUARRAY_CLASS_SUPPORT.md` |
| `mojor_gpu_kernel`, `gpu_kernel` | GPUArray runtime | gpu | `S3` | Mainly numeric lanes; backend dependent | Strict matrix2d subset now includes `seq_len(dim(X)[1L/2L])` loop-bounds equivalents, normalized zero-offset/`as.integer` index forms, runtime scalar neighbor offsets under explicit in-bounds guards, and negated/de-morgan bounds-guard forms in addition to canonical forms | Non-canonical index/guard/reduction forms still reject | Route/fallback depends on emitted kernel and backend capability; compiled raw-wrapper calls (`gpu_func_raw`) auto-align mixed GPUArray input dtypes to the kernel buffer dtype | `mojor_gpu: unsupported operator '<op>'` and matrix2d subset diagnostics | `docs/GPUARRAY_GUIDE.md`, `docs/TROUBLESHOOTING.md` |
| `mojor_gpu_sigmoid`, `mojor_gpu_affine`, `mojor_gpu_linear`, `mojor_gpu_chain_array`, `mojor_gpu_sum` | GPUArray runtime | both | `S2` | Mostly numeric host/GPU lanes | Legacy helper contracts over vectors/arrays | N/A | Mixed GPUArray/host paths with explicit route tagging where applicable | Helper input/type contract failures and route-dependent kernel availability errors | `docs/GPUARRAY_CLASS_SUPPORT.md`, `docs/COOKBOOK.md` |
| `mojor_gpu_session*` family | GPUArray runtime | gpu | `S2` | Primarily `f32` workflows; route/capability dependent | Session object lifecycle contracts apply | N/A | Mixed GPU/host behavior depending on path | Session type/lifecycle errors (`session must be mojor_gpu_session`) | `docs/GPUARRAY_CLASS_SUPPORT.md` |

## Cross-Reference Map

- IR-level GPU node contracts: `docs/IR/FUNCTION_SUPPORT_BREADTH.md`
- Runtime/class-level GPU support matrix: `docs/GPUARRAY_CLASS_SUPPORT.md`
- User workflows and examples: `docs/GPUARRAY_GUIDE.md`, `docs/COOKBOOK.md`
- Common failure diagnostics: `docs/DIAGNOSTICS_INDEX.md`, `docs/TROUBLESHOOTING.md`
